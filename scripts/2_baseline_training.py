#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BERT Baseline è®­ç»ƒè„šæœ¬ - ä½¿ç”¨æœ¬åœ°æ¨¡å‹
"""

import os
import sys
import json
import torch
import numpy as np
from pathlib import Path
from datetime import datetime
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

from transformers import (
    BertTokenizer,
    BertForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding
)
from datasets import load_from_disk
import matplotlib
matplotlib.rc("font",family='YouYuan')

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
MODELS_DIR = PROJECT_ROOT / "models"
RESULTS_DIR = PROJECT_ROOT / "results"

# åˆ›å»ºå¿…è¦çš„ç›®å½•
MODELS_DIR.mkdir(parents=True, exist_ok=True)
RESULTS_DIR.mkdir(parents=True, exist_ok=True)


class BERTBaselineTrainer:
    """BERT Baseline è®­ç»ƒå™¨"""

    def __init__(self, model_name="bert-base-chinese", use_quick_mode=False, use_local=False):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            model_name: é¢„è®­ç»ƒæ¨¡å‹åç§°
            use_quick_mode: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            use_local: æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        """
        self.use_local = use_local

        # å¦‚æœä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ŒæŒ‡å‘æœ¬åœ°è·¯å¾„
        if use_local:
            local_model_path = MODELS_DIR / model_name
            if not local_model_path.exists():
                raise FileNotFoundError(
                    f"æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨: {local_model_path}\n"
                    f"è¯·ç¡®ä¿å·²ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°è¯¥ç›®å½•"
                )
            self.model_name = str(local_model_path)
            print(f"ğŸ“ ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {local_model_path}")
        else:
            self.model_name = model_name
            # è®¾ç½®å›½å†…é•œåƒæº
            os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
            print(f"ğŸŒ ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name} (é•œåƒæº: {os.environ['HF_ENDPOINT']})")

        self.use_quick_mode = use_quick_mode
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # è¾“å‡ºç›®å½•
        self.output_dir = MODELS_DIR / "bert_baseline"
        self.results_dir = RESULTS_DIR / "baseline"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.results_dir.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ”§ å¿«é€Ÿæ¨¡å¼: {'å¼€å¯' if use_quick_mode else 'å…³é—­'}")

    def load_data(self):
        """åŠ è½½é¢„å¤„ç†åçš„æ•°æ®"""
        print("\nğŸ“Š åŠ è½½æ•°æ®...")

        processed_dir = DATA_DIR / "processed"
        self.train_dataset = load_from_disk(str(processed_dir / "train"))
        self.val_dataset = load_from_disk(str(processed_dir / "validation"))
        self.test_dataset = load_from_disk(str(processed_dir / "test"))

        # å¿«é€Ÿæ¨¡å¼ï¼šåªä½¿ç”¨å°‘é‡æ•°æ®
        if self.use_quick_mode:
            self.train_dataset = self.train_dataset.select(range(min(500, len(self.train_dataset))))
            self.val_dataset = self.val_dataset.select(range(min(100, len(self.val_dataset))))
            self.test_dataset = self.test_dataset.select(range(min(100, len(self.test_dataset))))
            print("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨å°‘é‡æ•°æ®è¿›è¡Œè®­ç»ƒ")

        print(f"è®­ç»ƒé›†: {len(self.train_dataset)} | "
              f"éªŒè¯é›†: {len(self.val_dataset)} | "
              f"æµ‹è¯•é›†: {len(self.test_dataset)}")

    def train(self):
        """è®­ç»ƒBERTæ¨¡å‹"""
        print("\n" + "=" * 60)
        print("ğŸš€ å¼€å§‹è®­ç»ƒBERT Baselineæ¨¡å‹")
        print("=" * 60)

        # åŠ è½½æ•°æ®
        self.load_data()

        # åŠ è½½tokenizerå’Œæ¨¡å‹
        print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {self.model_name}")
        try:
            tokenizer = BertTokenizer.from_pretrained(self.model_name)
            model = BertForSequenceClassification.from_pretrained(
                self.model_name,
                num_labels=2,
                use_safetensors=True  # æ”¯æŒ safetensors æ ¼å¼
            ).to(self.device)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print("\nğŸ’¡ å»ºè®®ï¼š")
            print("1. å¦‚æœæ˜¯ç½‘ç»œé—®é¢˜ï¼Œè¯·ä½¿ç”¨ --local å‚æ•°å¹¶æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹")
            print("2. æ‰‹åŠ¨ä¸‹è½½åœ°å€: https://hf-mirror.com/google-bert/bert-base-chinese")
            print("3. ä¸‹è½½åæ”¾åˆ°: models/bert-base-chinese/ ç›®å½•")
            raise

        # Tokenizeæ•°æ®
        def tokenize_function(examples):
            return tokenizer(
                examples["text"],
                padding="max_length",
                truncation=True,
                max_length=128
            )

        print("\nğŸ”„ Tokenizingæ•°æ®...")
        train_dataset = self.train_dataset.map(tokenize_function, batched=True)
        val_dataset = self.val_dataset.map(tokenize_function, batched=True)
        test_dataset = self.test_dataset.map(tokenize_function, batched=True)

        # è®¾ç½®è®­ç»ƒå‚æ•°
        if self.use_quick_mode:
            num_epochs = 1
            batch_size = 8  # å‡å°batch sizeé¿å…OOM
            save_steps = 100
        else:
            num_epochs = 3
            batch_size = 8  # å‡å°batch sizeé¿å…OOM
            save_steps = 500

        training_args = TrainingArguments(
            output_dir=str(self.output_dir),
            num_train_epochs=num_epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir=str(self.output_dir / "logs"),
            logging_steps=100,
            eval_strategy="steps",
            eval_steps=save_steps,
            save_strategy="steps",
            save_steps=save_steps,
            save_total_limit=2,
            load_best_model_at_end=True,
            metric_for_best_model="accuracy",
            report_to="none",
            fp16=torch.cuda.is_available(),
            gradient_accumulation_steps=2,  # æ¢¯åº¦ç´¯ç§¯ï¼Œå‡å°‘æ˜¾å­˜å ç”¨
            dataloader_pin_memory=False,  # å‡å°‘æ˜¾å­˜å ç”¨
        )

        # å®šä¹‰è¯„ä¼°æŒ‡æ ‡
        def compute_metrics(eval_pred):
            predictions, labels = eval_pred
            predictions = np.argmax(predictions, axis=1)

            from sklearn.metrics import accuracy_score, precision_recall_fscore_support
            accuracy = accuracy_score(labels, predictions)
            precision, recall, f1, _ = precision_recall_fscore_support(
                labels, predictions, average='binary'
            )

            return {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1
            }

        # åˆ›å»ºTrainer
        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            compute_metrics=compute_metrics,
            data_collator=data_collator,
        )

        # å¼€å§‹è®­ç»ƒ
        print("\nğŸ‹ï¸  å¼€å§‹è®­ç»ƒ...")
        train_result = trainer.train()

        # ä¿å­˜æ¨¡å‹
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        trainer.save_model(str(self.output_dir / "final"))
        tokenizer.save_pretrained(str(self.output_dir / "final"))

        # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
        metrics = train_result.metrics
        with open(self.results_dir / "train_metrics.json", "w", encoding="utf-8") as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)

        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {self.output_dir / 'final'}")

        return trainer

    def evaluate(self, trainer):
        """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
        print("\n" + "=" * 60)
        print("ğŸ“Š åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹")
        print("=" * 60)

        # Tokenizeæµ‹è¯•é›†ï¼ˆå¦‚æœè¿˜æ²¡æœ‰tokenizeï¼‰
        if 'input_ids' not in self.test_dataset.column_names:
            print("ğŸ”„ Tokenizingæµ‹è¯•é›†...")
            tokenizer = trainer.tokenizer

            def tokenize_function(examples):
                return tokenizer(
                    examples["text"],
                    padding="max_length",
                    truncation=True,
                    max_length=128
                )

            test_dataset_tokenized = self.test_dataset.map(tokenize_function, batched=True)
        else:
            test_dataset_tokenized = self.test_dataset

        # è¯„ä¼°
        metrics = trainer.evaluate(test_dataset_tokenized)

        # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
        with open(self.results_dir / "test_metrics.json", "w", encoding="utf-8") as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)

        # æ‰“å°ç»“æœ
        print("\næµ‹è¯•é›†ç»“æœ:")
        print(f"  Accuracy:  {metrics['eval_accuracy']:.4f}")
        print(f"  Precision: {metrics['eval_precision']:.4f}")
        print(f"  Recall:    {metrics['eval_recall']:.4f}")
        print(f"  F1 Score:  {metrics['eval_f1']:.4f}")

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self._generate_detailed_report(trainer)

        return metrics

    def _generate_detailed_report(self, trainer):
        """ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“ ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š...")

        # è·å–é¢„æµ‹ç»“æœ
        predictions = trainer.predict(self.test_dataset)
        pred_labels = np.argmax(predictions.predictions, axis=1)
        true_labels = predictions.label_ids

        # åˆ†ç±»æŠ¥å‘Š
        report = classification_report(
            true_labels,
            pred_labels,
            target_names=["Negative", "Positive"],
            digits=4
        )

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.results_dir / "classification_report.txt"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("BERT Baseline åˆ†ç±»æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(report)

        print(f"âœ… åˆ†ç±»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        self._plot_confusion_matrix(true_labels, pred_labels)

    def _plot_confusion_matrix(self, true_labels, pred_labels):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(true_labels, pred_labels)

        plt.figure(figsize=(8, 6))
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=["è´Ÿé¢", "æ­£é¢"],
            yticklabels=["è´Ÿé¢", "æ­£é¢"]
        )
        plt.title('BERT Baseline - æ··æ·†çŸ©é˜µ')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')

        # ä¿å­˜å›¾ç‰‡
        cm_path = self.results_dir / "confusion_matrix.png"
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {cm_path}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="è®­ç»ƒBERT Baselineæ¨¡å‹")
    parser.add_argument(
        "--quick",
        action="store_true",
        help="å¿«é€Ÿæ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="bert-base-chinese",
        help="é¢„è®­ç»ƒæ¨¡å‹åç§°"
    )
    parser.add_argument(
        "--local",
        action="store_true",
        help="ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆéœ€è¦æ‰‹åŠ¨ä¸‹è½½ï¼‰"
    )

    args = parser.parse_args()

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer_obj = BERTBaselineTrainer(
        model_name=args.model,
        use_quick_mode=args.quick,
        use_local=args.local
    )

    # è®­ç»ƒæ¨¡å‹
    trainer = trainer_obj.train()

    # è¯„ä¼°æ¨¡å‹
    metrics = trainer_obj.evaluate(trainer)

    print("\n" + "=" * 60)
    print("âœ… BERT Baselineè®­ç»ƒå®Œæˆï¼")
    print("=" * 60)
    print(f"\næœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {metrics['eval_accuracy']:.4f}")
    print(f"æ¨¡å‹ä¿å­˜ä½ç½®: {trainer_obj.output_dir / 'final'}")
    print(f"ç»“æœä¿å­˜ä½ç½®: {trainer_obj.results_dir}")


if __name__ == "__main__":
    main()
